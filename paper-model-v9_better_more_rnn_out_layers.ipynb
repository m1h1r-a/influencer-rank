{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13106630,"sourceType":"datasetVersion","datasetId":8302160}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import os\n# os.system('pip uninstall torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib -y')\n\n# !pip install torch==2.3.1+cu121 torchvision==0.18.1+cu121 torchaudio==2.3.1+cu121 --index-url https://download.pytorch.org/whl/cu121\n\n# !pip install torch-scatter==2.1.2+pt23cu121 torch-sparse==0.6.18+pt23cu121 torch-cluster==1.6.3+pt23cu121 torch-spline-conv==1.2.2+pt23cu121 -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n\n# !pip install torch-geometric\n# !pip install pyg-lib -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n\n# import os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T17:18:07.869555Z","iopub.execute_input":"2025-09-20T17:18:07.870283Z","iopub.status.idle":"2025-09-20T17:18:07.873525Z","shell.execute_reply.started":"2025-09-20T17:18:07.870259Z","shell.execute_reply":"2025-09-20T17:18:07.872924Z"}},"outputs":[],"execution_count":119},{"cell_type":"code","source":"print(\"Starting\")\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nfrom torch.nn.utils.rnn import pad_sequence\nfrom tqdm import tqdm\nimport os\nimport math\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T17:18:07.876514Z","iopub.execute_input":"2025-09-20T17:18:07.877111Z","iopub.status.idle":"2025-09-20T17:18:07.891264Z","shell.execute_reply.started":"2025-09-20T17:18:07.877094Z","shell.execute_reply":"2025-09-20T17:18:07.890548Z"}},"outputs":[{"name":"stdout","text":"Starting\nUsing device: cuda\n","output_type":"stream"}],"execution_count":120},{"cell_type":"code","source":"def convert_hetero_to_homogeneous(hetero_data):\n    \"\"\"\n    Converts a HeteroData object to a homogeneous graph format that a standard\n    GCNConv layer can process. It also returns a mask to identify influencers.\n    \"\"\"\n    # Create a single large feature matrix by concatenating features of all node types\n    x = torch.cat([hetero_data[node_type].x for node_type in hetero_data.node_types], dim=0)\n    \n    # Create offsets to map original node indices to the new homogeneous indices\n    offsets = {}\n    current_offset = 0\n    for node_type in hetero_data.node_types:\n        offsets[node_type] = current_offset\n        current_offset += hetero_data[node_type].num_nodes\n        \n    # Combine edge indices, adjusting them with the offsets\n    edge_indices = []\n    for src, _, dst in hetero_data.edge_types:\n        edge_index = hetero_data[(src, _, dst)].edge_index\n        edge_index[0] += offsets[src]\n        edge_index[1] += offsets[dst]\n        edge_indices.append(edge_index)\n    edge_index = torch.cat(edge_indices, dim=1)\n\n    # Create a boolean mask to identify which nodes in the homogeneous graph are influencers\n    influencer_mask = torch.zeros(x.size(0), dtype=torch.bool)\n    influencer_offset = offsets['influencer']\n    num_influencers = hetero_data['influencer'].num_nodes\n    influencer_mask[influencer_offset : influencer_offset + num_influencers] = True\n    \n    return x, edge_index, influencer_mask\n\nclass PaperGNNEncoder(nn.Module):\n    \"\"\"The simple GCN Encoder block from the paper.\"\"\"\n    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):\n        super().__init__()\n        self.conv1 = GCNConv(in_channels, hidden_channels)\n        self.conv2 = GCNConv(hidden_channels, out_channels)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, edge_index):\n        x = F.relu(self.conv1(x, edge_index))\n        x = self.dropout(x)\n        x = self.conv2(x, edge_index)\n        return x\n\nprint(\"Helper functions and GNN Encoder defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T17:18:07.892604Z","iopub.execute_input":"2025-09-20T17:18:07.892837Z","iopub.status.idle":"2025-09-20T17:18:07.903863Z","shell.execute_reply.started":"2025-09-20T17:18:07.892818Z","shell.execute_reply":"2025-09-20T17:18:07.903167Z"}},"outputs":[{"name":"stdout","text":"Helper functions and GNN Encoder defined.\n","output_type":"stream"}],"execution_count":121},{"cell_type":"code","source":"class FastInfluencerRank(nn.Module):\n    \"\"\"Phase 2: Lightning-fast model that only processes pre-computed embeddings\"\"\"\n    def __init__(self, gnn_out, rnn_hidden, dropout=0.5):\n        super().__init__()\n        # NO GNN - only RNN and final layers for speed\n        self.rnn = nn.GRU(input_size=gnn_out, hidden_size=rnn_hidden, batch_first=True)\n        self.attention = nn.Linear(rnn_hidden, 1)\n        self.fc1 = nn.Linear(rnn_hidden, rnn_hidden // 2)\n        self.fc2 = nn.Linear(rnn_hidden // 2, 1)\n        self.dropout = nn.Dropout(dropout)\n    \n    def create_attention_mask(self, lengths, max_len):\n        batch_size = len(lengths)\n        mask = torch.arange(max_len, device=lengths.device).expand(batch_size, max_len) < lengths.unsqueeze(1)\n        return mask\n    \n    def forward(self, precomputed_sequences, valid_lengths):\n        \"\"\"\n        precomputed_sequences: [batch_size, max_months, embedding_dim]\n        valid_lengths: [batch_size] - number of valid months per influencer\n        \"\"\"\n        if precomputed_sequences.size(0) == 0:\n            return torch.tensor([], device=precomputed_sequences.device)\n        \n        # RNN processing\n        rnn_out, _ = self.rnn(precomputed_sequences)\n        \n        # Attention with masking\n        attention_scores = self.attention(rnn_out).squeeze(-1)\n        attention_mask = self.create_attention_mask(valid_lengths, precomputed_sequences.size(1))\n        attention_scores = attention_scores.masked_fill(~attention_mask, float('-inf'))\n        attention_weights = torch.softmax(attention_scores, dim=1).unsqueeze(-1)\n        \n        # Weighted sum\n        context = torch.sum(attention_weights * rnn_out, dim=1)\n        \n        # Final prediction\n        x = F.relu(self.fc1(context))\n        x = self.dropout(x)\n        scores = self.fc2(x)\n        \n        return scores.squeeze(-1)\n\nprint(\"Fast two-phase model architecture defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T17:18:07.904676Z","iopub.execute_input":"2025-09-20T17:18:07.904893Z","iopub.status.idle":"2025-09-20T17:18:07.920477Z","shell.execute_reply.started":"2025-09-20T17:18:07.904869Z","shell.execute_reply":"2025-09-20T17:18:07.919938Z"}},"outputs":[{"name":"stdout","text":"Fast two-phase model architecture defined.\n","output_type":"stream"}],"execution_count":122},{"cell_type":"code","source":"def precompute_all_gnn_embeddings():\n    \"\"\"Phase 1: Run GNN once on all graphs to 'bake' embeddings\"\"\"\n    print(\"=== PHASE 1: Pre-computing GNN embeddings ===\")\n    \n    # Hyperparameters\n    NODE_FEATURES = FINAL_FEATURE_DIM\n    GNN_HIDDEN = 128\n    GNN_OUT = 128\n    \n    # Initialize just the GNN encoder\n    gnn_encoder = PaperGNNEncoder(NODE_FEATURES, GNN_HIDDEN, GNN_OUT).to(device)\n    gnn_encoder.eval()\n    \n    monthly_embeddings = {}\n    \n    with torch.no_grad():\n        for month_idx, (x, edge_index, influencer_mask) in enumerate(tqdm(homogeneous_graphs, desc=\"Processing months\")):\n            # Move data to GPU\n            x = x.to(device)\n            edge_index = edge_index.to(device)\n            \n            # Get embeddings for all nodes\n            all_embeddings = gnn_encoder(x, edge_index)\n            \n            # Extract only influencer embeddings and move to CPU\n            influencer_embeddings = all_embeddings[influencer_mask].cpu()\n            monthly_embeddings[month_idx] = influencer_embeddings\n            \n            print(f\"Month {month_idx}: {influencer_embeddings.shape[0]} influencer embeddings\")\n    \n    # Save embeddings\n    torch.save(monthly_embeddings, 'precomputed_embeddings.pt')\n    print(\"Phase 1 complete! Embeddings saved to 'precomputed_embeddings.pt'\")\n    \n    # Clear GPU memory\n    del gnn_encoder\n    torch.cuda.empty_cache()\n    \n    return monthly_embeddings\n\n# Run Phase 1\nmonthly_embeddings = precompute_all_gnn_embeddings()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T17:18:07.921653Z","iopub.execute_input":"2025-09-20T17:18:07.921867Z","iopub.status.idle":"2025-09-20T17:18:08.317834Z","shell.execute_reply.started":"2025-09-20T17:18:07.921853Z","shell.execute_reply":"2025-09-20T17:18:08.317244Z"}},"outputs":[{"name":"stdout","text":"=== PHASE 1: Pre-computing GNN embeddings ===\n","output_type":"stream"},{"name":"stderr","text":"Processing months:  25%|██▌       | 3/12 [00:00<00:00, 29.30it/s]","output_type":"stream"},{"name":"stdout","text":"Month 0: 3258 influencer embeddings\nMonth 1: 4465 influencer embeddings\nMonth 2: 5973 influencer embeddings\nMonth 3: 2745 influencer embeddings\nMonth 4: 2556 influencer embeddings\nMonth 5: 4136 influencer embeddings\nMonth 6: 3831 influencer embeddings\nMonth 7: 2998 influencer embeddings\n","output_type":"stream"},{"name":"stderr","text":"Processing months:  75%|███████▌  | 9/12 [00:00<00:00, 43.19it/s]","output_type":"stream"},{"name":"stdout","text":"Month 8: 3549 influencer embeddings\n","output_type":"stream"},{"name":"stderr","text":"Processing months: 100%|██████████| 12/12 [00:00<00:00, 36.93it/s]","output_type":"stream"},{"name":"stdout","text":"Month 9: 5545 influencer embeddings\nMonth 10: 5180 influencer embeddings\nMonth 11: 4808 influencer embeddings\nPhase 1 complete! Embeddings saved to 'precomputed_embeddings.pt'\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":123},{"cell_type":"code","source":"GRAPH_DIR = '/kaggle/input/influencer-rank/graphs'\nall_graphs_data = [torch.load(os.path.join(GRAPH_DIR, f), map_location='cpu', weights_only=False) \n                   for f in sorted(os.listdir(GRAPH_DIR)) if f.endswith('.pt')]\nprint(f\"Loaded {len(all_graphs_data)} monthly data packages.\")\n\n# --- Feature preparation ---\nfor data_package in all_graphs_data:\n    graph = data_package['graph']\n    if 'x' in graph['influencer']:\n        graph['influencer'].x_original = graph['influencer'].x.clone()\n        # columns_to_keep = [0, 1, 2, 3, 4]\n        columns_to_keep = list(range(min(5, graph['influencer'].x_original.shape[1])))\n        graph['influencer'].x = graph['influencer'].x[:, columns_to_keep]\n\n# --- Feature Normalization ---\nprint(\"Normalizing features...\")\nall_features_list = []\nfor data_package in all_graphs_data:\n    if 'x' in data_package['graph']['influencer'] and data_package['graph']['influencer'].x.numel() > 0:\n        all_features_list.append(data_package['graph']['influencer'].x.numpy())\n\nif all_features_list:\n    all_features_combined = np.vstack(all_features_list)\n    scaler = StandardScaler()\n    scaler.fit(all_features_combined)\n\n    for data_package in all_graphs_data:\n        if 'x' in data_package['graph']['influencer'] and data_package['graph']['influencer'].x.numel() > 0:\n            normalized_features = scaler.transform(data_package['graph']['influencer'].x.numpy())\n            data_package['graph']['influencer'].x = torch.FloatTensor(normalized_features)\nprint(\"Feature normalization complete.\")\n\n# --- Zero-pad other node types ---\nFINAL_FEATURE_DIM = all_graphs_data[0]['graph']['influencer'].x.shape[1]\nfor data_package in all_graphs_data:\n    for node_type in ['hashtag', 'user', 'object']:\n        num_nodes = data_package['graph'][node_type].num_nodes\n        data_package['graph'][node_type].x = torch.zeros(num_nodes, FINAL_FEATURE_DIM)\nprint(\"All data loaded and prepared.\")\n\n# --- Pre-convert graphs to homogeneous format (for speed) ---\nprint(\"Pre-converting graphs to homogeneous format...\")\nhomogeneous_graphs = [convert_hetero_to_homogeneous(data['graph']) for data in tqdm(all_graphs_data)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T17:18:08.318917Z","iopub.execute_input":"2025-09-20T17:18:08.319179Z","iopub.status.idle":"2025-09-20T17:18:09.041933Z","shell.execute_reply.started":"2025-09-20T17:18:08.319161Z","shell.execute_reply":"2025-09-20T17:18:09.041092Z"}},"outputs":[{"name":"stdout","text":"Loaded 12 monthly data packages.\nNormalizing features...\nFeature normalization complete.\nAll data loaded and prepared.\nPre-converting graphs to homogeneous format...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12/12 [00:00<00:00, 482.75it/s]\n","output_type":"stream"}],"execution_count":124},{"cell_type":"code","source":"def prepare_precomputed_batch(monthly_embeddings, batch_names, local_maps):\n    \"\"\"Prepare batch using pre-computed embeddings\"\"\"\n    batch_sequences = []\n    valid_lengths = []\n    \n    for name in batch_names:\n        sequence = []\n        for month_idx in range(len(local_maps)):\n            if name in local_maps[month_idx]:\n                local_idx = local_maps[month_idx][name]\n                if local_idx < monthly_embeddings[month_idx].shape[0]:\n                    embedding = monthly_embeddings[month_idx][local_idx]\n                    sequence.append(embedding)\n        \n        if sequence:\n            valid_lengths.append(len(sequence))\n            batch_sequences.append(torch.stack(sequence))\n    \n    if not batch_sequences:\n        return torch.tensor([]), torch.tensor([])\n    \n    # Pad sequences\n    padded_sequences = pad_sequence(batch_sequences, batch_first=True, padding_value=0.0)\n    valid_lengths = torch.tensor(valid_lengths)\n    \n    return padded_sequences, valid_lengths\n\nprint(\"Fast batch preparation function defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T17:18:09.042770Z","iopub.execute_input":"2025-09-20T17:18:09.043014Z","iopub.status.idle":"2025-09-20T17:18:09.049516Z","shell.execute_reply.started":"2025-09-20T17:18:09.042990Z","shell.execute_reply":"2025-09-20T17:18:09.048757Z"}},"outputs":[{"name":"stdout","text":"Fast batch preparation function defined.\n","output_type":"stream"}],"execution_count":125},{"cell_type":"code","source":"# Hyperparameters\nGNN_OUT = 128  \nRNN_HIDDEN = 128\nBATCH_SIZE = 32\nLEARNING_RATE = 0.001\n\n# Initialize fast model\nmodel = FastInfluencerRank(GNN_OUT, RNN_HIDDEN).to(device)\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n\ndef listwise_ranking_loss(y_pred, y_true):\n    y_pred_diff = y_pred.unsqueeze(1) - y_pred.unsqueeze(0)\n    y_true_diff = y_true.unsqueeze(1) - y_true.unsqueeze(0)\n    mask = (y_true_diff > 0).float()\n    loss = torch.log(1 + torch.exp(-y_pred_diff)) * mask\n    return torch.sum(loss) / torch.sum(mask).clamp(min=1)\n\n# Data splits\ntrain_local_maps = [d['maps']['influencer'] for d in all_graphs_data[:10]]\nval_local_maps = [d['maps']['influencer'] for d in all_graphs_data[:11]]\n\ntrain_influencers = sorted(list(set(name for month_map in train_local_maps for name in month_map.keys())))\nval_influencers = sorted(list(set(name for month_map in val_local_maps for name in month_map.keys())))\n\nprint(f\"=== PHASE 2: Lightning-fast training ===\")\nprint(f\"Training influencers: {len(train_influencers)}\")\n\n# Sanity check\nprint(\"\\n--- Quick Sanity Check ---\")\ntest_batch_names = train_influencers[:3]\ntest_sequences, test_lengths = prepare_precomputed_batch(monthly_embeddings, test_batch_names, train_local_maps)\n\ny_true_target_graph = all_graphs_data[9]['graph']['influencer']\ny_true_target_map = all_graphs_data[9]['maps']['influencer']\nvalid_names = [name for name in test_batch_names if name in y_true_target_map]\ny_true_indices = [y_true_target_map[name] for name in valid_names]\ny_true_batch = y_true_target_graph.x_original[y_true_indices, 5].to(device)\n\nmodel.train()\nscores = model(test_sequences.to(device), test_lengths.to(device))\nprint(f\"Scores shape: {scores.shape}, Y_true shape: {y_true_batch.shape}\")\n\nif scores.shape[0] == y_true_batch.shape[0]:\n    print(\"✅ Sanity check passed!\")\nelse:\n    print(\"❌ Shape mismatch!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T17:18:09.050784Z","iopub.execute_input":"2025-09-20T17:18:09.051079Z","iopub.status.idle":"2025-09-20T17:18:09.085814Z","shell.execute_reply.started":"2025-09-20T17:18:09.051062Z","shell.execute_reply":"2025-09-20T17:18:09.085258Z"}},"outputs":[{"name":"stdout","text":"=== PHASE 2: Lightning-fast training ===\nTraining influencers: 6113\n\n--- Quick Sanity Check ---\nScores shape: torch.Size([3]), Y_true shape: torch.Size([3])\n✅ Sanity check passed!\n","output_type":"stream"}],"execution_count":126},{"cell_type":"code","source":"def ndcg_score(y_true, y_pred, k=50):\n    if len(y_true) < 2: return 0.0\n    order = torch.argsort(y_pred, descending=True)\n    y_true_sorted = y_true[order]\n    dcg = sum(y_true_sorted[i] / math.log2(i + 2) for i in range(min(k, len(y_true_sorted))))\n    ideal_order = torch.argsort(y_true, descending=True)\n    y_true_ideal_sorted = y_true[ideal_order]\n    idcg = sum(y_true_ideal_sorted[i] / math.log2(i + 2) for i in range(min(k, len(y_true_ideal_sorted))))\n    return dcg / idcg if idcg > 0 else 0.0\n\nprint(\"Starting lightning-fast training...\")\nbest_val_ndcg = -1\nNUM_EPOCHS = 250\n\nfor epoch in range(NUM_EPOCHS):\n    model.train()\n    epoch_losses = []\n    \n    # Shuffle influencers\n    shuffled_influencers = torch.randperm(len(train_influencers))\n    \n    for i in tqdm(range(0, len(train_influencers), BATCH_SIZE), desc=f\"Epoch {epoch+1}\", leave=False):\n        batch_indices = shuffled_influencers[i:i+BATCH_SIZE]\n        batch_names = [train_influencers[j] for j in batch_indices]\n        \n        # Get ground truth\n        y_true_target_graph = all_graphs_data[9]['graph']['influencer']\n        y_true_target_map = all_graphs_data[9]['maps']['influencer']\n        valid_names = [name for name in batch_names if name in y_true_target_map]\n        \n        if len(valid_names) < 2:\n            continue\n            \n        y_true_indices = [y_true_target_map[name] for name in valid_names]\n        y_true_batch = y_true_target_graph.x_original[y_true_indices, 5].to(device)\n        \n        # Prepare batch (lightning fast!)\n        sequences, lengths = prepare_precomputed_batch(monthly_embeddings, valid_names, train_local_maps)\n        \n        if sequences.size(0) == 0:\n            continue\n            \n        optimizer.zero_grad()\n        scores = model(sequences.to(device), lengths.to(device))\n        \n        if scores.shape[0] != y_true_batch.shape[0]:\n            continue\n            \n        loss = listwise_ranking_loss(scores, y_true_batch)\n        \n        if not torch.isnan(loss):\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            epoch_losses.append(loss.item())\n    \n    # Validation\n    if epoch_losses:\n        model.eval()\n        with torch.no_grad():\n            # Sample validation influencers for speed\n            val_sample = val_influencers[:1000]  # Sample for speed\n            y_true_val_graph = all_graphs_data[10]['graph']['influencer']\n            y_true_val_map = all_graphs_data[10]['maps']['influencer']\n            valid_val_names = [name for name in val_sample if name in y_true_val_map]\n            \n            if valid_val_names:\n                y_true_val_indices = [y_true_val_map[name] for name in valid_val_names]\n                y_true_val = y_true_val_graph.x_original[y_true_val_indices, 5]\n                \n                val_sequences, val_lengths = prepare_precomputed_batch(monthly_embeddings, valid_val_names, val_local_maps)\n                \n                if val_sequences.size(0) > 0:\n                    val_scores = model(val_sequences.to(device), val_lengths.to(device))\n                    if val_scores.shape[0] == y_true_val.shape[0]:\n                        val_ndcg = ndcg_score(y_true_val, val_scores.cpu())\n                    else:\n                        val_ndcg = 0.0\n                else:\n                    val_ndcg = 0.0\n            else:\n                val_ndcg = 0.0\n        \n        avg_loss = np.mean(epoch_losses)\n        print(f\"Epoch {epoch+1} - Loss: {avg_loss:.4f}, Val NDCG@50: {val_ndcg:.4f}\")\n        \n        if val_ndcg > best_val_ndcg:\n            best_val_ndcg = val_ndcg\n            torch.save(model.state_dict(), 'best_fast_model.pth')\n\nprint(f\"Training complete! Best validation NDCG@50: {best_val_ndcg:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T17:18:09.086585Z","iopub.execute_input":"2025-09-20T17:18:09.086804Z","iopub.status.idle":"2025-09-20T17:21:59.432471Z","shell.execute_reply.started":"2025-09-20T17:18:09.086788Z","shell.execute_reply":"2025-09-20T17:21:59.431821Z"}},"outputs":[{"name":"stdout","text":"Starting lightning-fast training...\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 - Loss: 0.6844, Val NDCG@50: 0.3201\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 - Loss: 0.6802, Val NDCG@50: 0.2877\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 - Loss: 0.6797, Val NDCG@50: 0.3083\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 - Loss: 0.6770, Val NDCG@50: 0.3267\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 - Loss: 0.6771, Val NDCG@50: 0.3284\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 - Loss: 0.6758, Val NDCG@50: 0.3192\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 - Loss: 0.6760, Val NDCG@50: 0.3266\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 - Loss: 0.6733, Val NDCG@50: 0.3385\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9 - Loss: 0.6757, Val NDCG@50: 0.2679\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10 - Loss: 0.6736, Val NDCG@50: 0.3420\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11 - Loss: 0.6762, Val NDCG@50: 0.3426\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12 - Loss: 0.6728, Val NDCG@50: 0.2992\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13 - Loss: 0.6734, Val NDCG@50: 0.3630\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14 - Loss: 0.6710, Val NDCG@50: 0.2628\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15 - Loss: 0.6729, Val NDCG@50: 0.3513\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16 - Loss: 0.6732, Val NDCG@50: 0.3686\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17 - Loss: 0.6718, Val NDCG@50: 0.3641\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18 - Loss: 0.6709, Val NDCG@50: 0.4175\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19 - Loss: 0.6726, Val NDCG@50: 0.3846\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20 - Loss: 0.6703, Val NDCG@50: 0.3803\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21 - Loss: 0.6708, Val NDCG@50: 0.3825\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22 - Loss: 0.6717, Val NDCG@50: 0.3790\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23 - Loss: 0.6697, Val NDCG@50: 0.4160\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24 - Loss: 0.6702, Val NDCG@50: 0.4047\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 25 - Loss: 0.6705, Val NDCG@50: 0.4423\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 26 - Loss: 0.6688, Val NDCG@50: 0.3536\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 27 - Loss: 0.6687, Val NDCG@50: 0.3991\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 28 - Loss: 0.6692, Val NDCG@50: 0.3873\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 29 - Loss: 0.6672, Val NDCG@50: 0.3365\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 30 - Loss: 0.6670, Val NDCG@50: 0.3647\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 31 - Loss: 0.6680, Val NDCG@50: 0.3996\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 32 - Loss: 0.6649, Val NDCG@50: 0.3917\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 33 - Loss: 0.6659, Val NDCG@50: 0.3289\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 34 - Loss: 0.6681, Val NDCG@50: 0.4020\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 35 - Loss: 0.6657, Val NDCG@50: 0.3980\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 36 - Loss: 0.6668, Val NDCG@50: 0.3536\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 37 - Loss: 0.6662, Val NDCG@50: 0.4041\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 38 - Loss: 0.6640, Val NDCG@50: 0.3972\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 39 - Loss: 0.6649, Val NDCG@50: 0.3871\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 40 - Loss: 0.6649, Val NDCG@50: 0.4299\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 41 - Loss: 0.6616, Val NDCG@50: 0.4046\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 42 - Loss: 0.6614, Val NDCG@50: 0.4081\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 43 - Loss: 0.6629, Val NDCG@50: 0.4522\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 44 - Loss: 0.6626, Val NDCG@50: 0.4847\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 45 - Loss: 0.6620, Val NDCG@50: 0.4071\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 46 - Loss: 0.6606, Val NDCG@50: 0.4656\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 47 - Loss: 0.6616, Val NDCG@50: 0.4497\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 48 - Loss: 0.6581, Val NDCG@50: 0.4855\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 49 - Loss: 0.6584, Val NDCG@50: 0.4124\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 50 - Loss: 0.6582, Val NDCG@50: 0.4312\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 51 - Loss: 0.6576, Val NDCG@50: 0.4383\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 52 - Loss: 0.6585, Val NDCG@50: 0.4212\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 53 - Loss: 0.6566, Val NDCG@50: 0.4210\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 54 - Loss: 0.6546, Val NDCG@50: 0.4470\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 55 - Loss: 0.6532, Val NDCG@50: 0.4548\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 56 - Loss: 0.6533, Val NDCG@50: 0.3879\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 57 - Loss: 0.6518, Val NDCG@50: 0.3937\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 58 - Loss: 0.6510, Val NDCG@50: 0.4265\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 59 - Loss: 0.6496, Val NDCG@50: 0.4245\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 60 - Loss: 0.6490, Val NDCG@50: 0.4414\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 61 - Loss: 0.6492, Val NDCG@50: 0.4325\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 62 - Loss: 0.6503, Val NDCG@50: 0.3817\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 63 - Loss: 0.6469, Val NDCG@50: 0.4135\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 64 - Loss: 0.6501, Val NDCG@50: 0.4165\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 65 - Loss: 0.6476, Val NDCG@50: 0.4261\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 66 - Loss: 0.6472, Val NDCG@50: 0.3895\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 67 - Loss: 0.6447, Val NDCG@50: 0.4180\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 68 - Loss: 0.6434, Val NDCG@50: 0.4136\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 69 - Loss: 0.6413, Val NDCG@50: 0.4013\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 70 - Loss: 0.6444, Val NDCG@50: 0.3627\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 71 - Loss: 0.6407, Val NDCG@50: 0.3548\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 72 - Loss: 0.6404, Val NDCG@50: 0.3978\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 73 - Loss: 0.6389, Val NDCG@50: 0.4018\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 74 - Loss: 0.6358, Val NDCG@50: 0.4175\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 75 - Loss: 0.6330, Val NDCG@50: 0.4358\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 76 - Loss: 0.6323, Val NDCG@50: 0.4221\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 77 - Loss: 0.6324, Val NDCG@50: 0.3904\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 78 - Loss: 0.6320, Val NDCG@50: 0.3621\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 79 - Loss: 0.6312, Val NDCG@50: 0.3781\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 80 - Loss: 0.6275, Val NDCG@50: 0.3653\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 81 - Loss: 0.6233, Val NDCG@50: 0.3607\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 82 - Loss: 0.6245, Val NDCG@50: 0.3915\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 83 - Loss: 0.6223, Val NDCG@50: 0.3943\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 84 - Loss: 0.6207, Val NDCG@50: 0.3946\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 85 - Loss: 0.6226, Val NDCG@50: 0.4138\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 86 - Loss: 0.6165, Val NDCG@50: 0.4099\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 87 - Loss: 0.6163, Val NDCG@50: 0.3786\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 88 - Loss: 0.6151, Val NDCG@50: 0.4037\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 89 - Loss: 0.6141, Val NDCG@50: 0.4236\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 90 - Loss: 0.6091, Val NDCG@50: 0.4002\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 91 - Loss: 0.6088, Val NDCG@50: 0.4195\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 92 - Loss: 0.6050, Val NDCG@50: 0.4093\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 93 - Loss: 0.6067, Val NDCG@50: 0.4131\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 94 - Loss: 0.6012, Val NDCG@50: 0.4500\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 95 - Loss: 0.5997, Val NDCG@50: 0.4604\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 96 - Loss: 0.5969, Val NDCG@50: 0.4507\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 97 - Loss: 0.5949, Val NDCG@50: 0.4519\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 98 - Loss: 0.5914, Val NDCG@50: 0.4720\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 99 - Loss: 0.5944, Val NDCG@50: 0.4186\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 100 - Loss: 0.5887, Val NDCG@50: 0.4540\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 101 - Loss: 0.5882, Val NDCG@50: 0.4231\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 102 - Loss: 0.5855, Val NDCG@50: 0.4954\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 103 - Loss: 0.5813, Val NDCG@50: 0.4440\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 104 - Loss: 0.5817, Val NDCG@50: 0.4523\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 105 - Loss: 0.5766, Val NDCG@50: 0.5182\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 106 - Loss: 0.5810, Val NDCG@50: 0.4999\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 107 - Loss: 0.5762, Val NDCG@50: 0.5164\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 108 - Loss: 0.5749, Val NDCG@50: 0.5106\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 109 - Loss: 0.5721, Val NDCG@50: 0.5012\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 110 - Loss: 0.5664, Val NDCG@50: 0.4920\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 111 - Loss: 0.5669, Val NDCG@50: 0.5082\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 112 - Loss: 0.5677, Val NDCG@50: 0.5243\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 113 - Loss: 0.5625, Val NDCG@50: 0.4990\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 114 - Loss: 0.5596, Val NDCG@50: 0.5447\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 115 - Loss: 0.5567, Val NDCG@50: 0.5338\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 116 - Loss: 0.5550, Val NDCG@50: 0.4708\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 117 - Loss: 0.5554, Val NDCG@50: 0.4546\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 118 - Loss: 0.5527, Val NDCG@50: 0.4806\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 119 - Loss: 0.5484, Val NDCG@50: 0.4924\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 120 - Loss: 0.5470, Val NDCG@50: 0.4966\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 121 - Loss: 0.5449, Val NDCG@50: 0.4700\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 122 - Loss: 0.5478, Val NDCG@50: 0.5592\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 123 - Loss: 0.5384, Val NDCG@50: 0.5186\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 124 - Loss: 0.5403, Val NDCG@50: 0.5330\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 125 - Loss: 0.5377, Val NDCG@50: 0.5044\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 126 - Loss: 0.5350, Val NDCG@50: 0.5032\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 127 - Loss: 0.5358, Val NDCG@50: 0.5554\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 128 - Loss: 0.5309, Val NDCG@50: 0.4758\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 129 - Loss: 0.5318, Val NDCG@50: 0.5476\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 130 - Loss: 0.5216, Val NDCG@50: 0.5349\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 131 - Loss: 0.5237, Val NDCG@50: 0.5631\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 132 - Loss: 0.5205, Val NDCG@50: 0.5366\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 133 - Loss: 0.5217, Val NDCG@50: 0.5513\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 134 - Loss: 0.5179, Val NDCG@50: 0.5906\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 135 - Loss: 0.5182, Val NDCG@50: 0.5812\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 136 - Loss: 0.5141, Val NDCG@50: 0.5666\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 137 - Loss: 0.5139, Val NDCG@50: 0.5463\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 138 - Loss: 0.5074, Val NDCG@50: 0.5600\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 139 - Loss: 0.5064, Val NDCG@50: 0.5110\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 140 - Loss: 0.5086, Val NDCG@50: 0.5330\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 141 - Loss: 0.5044, Val NDCG@50: 0.5348\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 142 - Loss: 0.5015, Val NDCG@50: 0.5290\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 143 - Loss: 0.4963, Val NDCG@50: 0.5848\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 144 - Loss: 0.4986, Val NDCG@50: 0.5009\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 145 - Loss: 0.4900, Val NDCG@50: 0.5580\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 146 - Loss: 0.4891, Val NDCG@50: 0.5360\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 147 - Loss: 0.4911, Val NDCG@50: 0.5201\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 148 - Loss: 0.4879, Val NDCG@50: 0.5703\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 149 - Loss: 0.4851, Val NDCG@50: 0.5534\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 150 - Loss: 0.4808, Val NDCG@50: 0.5598\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 151 - Loss: 0.4760, Val NDCG@50: 0.6254\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 152 - Loss: 0.4737, Val NDCG@50: 0.6192\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 153 - Loss: 0.4749, Val NDCG@50: 0.6158\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 154 - Loss: 0.4705, Val NDCG@50: 0.5599\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 155 - Loss: 0.4724, Val NDCG@50: 0.6026\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 156 - Loss: 0.4675, Val NDCG@50: 0.5950\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 157 - Loss: 0.4648, Val NDCG@50: 0.6268\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 158 - Loss: 0.4628, Val NDCG@50: 0.5901\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 159 - Loss: 0.4607, Val NDCG@50: 0.6273\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 160 - Loss: 0.4562, Val NDCG@50: 0.5520\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 161 - Loss: 0.4554, Val NDCG@50: 0.5753\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 162 - Loss: 0.4512, Val NDCG@50: 0.5547\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 163 - Loss: 0.4532, Val NDCG@50: 0.6101\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 164 - Loss: 0.4489, Val NDCG@50: 0.6214\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 165 - Loss: 0.4491, Val NDCG@50: 0.5897\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 166 - Loss: 0.4446, Val NDCG@50: 0.5995\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 167 - Loss: 0.4407, Val NDCG@50: 0.5469\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 168 - Loss: 0.4373, Val NDCG@50: 0.5930\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 169 - Loss: 0.4304, Val NDCG@50: 0.5892\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 170 - Loss: 0.4338, Val NDCG@50: 0.5577\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 171 - Loss: 0.4338, Val NDCG@50: 0.5914\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 172 - Loss: 0.4264, Val NDCG@50: 0.5378\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 173 - Loss: 0.4238, Val NDCG@50: 0.5189\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 174 - Loss: 0.4253, Val NDCG@50: 0.5175\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 175 - Loss: 0.4231, Val NDCG@50: 0.6419\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 176 - Loss: 0.4188, Val NDCG@50: 0.5215\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 177 - Loss: 0.4230, Val NDCG@50: 0.5774\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 178 - Loss: 0.4201, Val NDCG@50: 0.5048\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 179 - Loss: 0.4177, Val NDCG@50: 0.5612\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 180 - Loss: 0.4151, Val NDCG@50: 0.5240\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 181 - Loss: 0.4131, Val NDCG@50: 0.5887\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 182 - Loss: 0.4085, Val NDCG@50: 0.5391\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 183 - Loss: 0.4120, Val NDCG@50: 0.5960\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 184 - Loss: 0.4102, Val NDCG@50: 0.5556\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 185 - Loss: 0.4072, Val NDCG@50: 0.5865\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 186 - Loss: 0.4026, Val NDCG@50: 0.5419\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 187 - Loss: 0.4007, Val NDCG@50: 0.5512\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 188 - Loss: 0.3973, Val NDCG@50: 0.5983\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 189 - Loss: 0.3979, Val NDCG@50: 0.5164\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 190 - Loss: 0.3899, Val NDCG@50: 0.5444\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 191 - Loss: 0.3975, Val NDCG@50: 0.5498\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 192 - Loss: 0.3929, Val NDCG@50: 0.6174\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 193 - Loss: 0.3901, Val NDCG@50: 0.5891\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 194 - Loss: 0.3859, Val NDCG@50: 0.6393\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 195 - Loss: 0.3871, Val NDCG@50: 0.5596\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 196 - Loss: 0.3824, Val NDCG@50: 0.5939\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 197 - Loss: 0.3853, Val NDCG@50: 0.5591\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 198 - Loss: 0.3796, Val NDCG@50: 0.5954\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 199 - Loss: 0.3777, Val NDCG@50: 0.5796\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 200 - Loss: 0.3750, Val NDCG@50: 0.6038\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 201 - Loss: 0.3783, Val NDCG@50: 0.5603\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 202 - Loss: 0.3728, Val NDCG@50: 0.5401\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 203 - Loss: 0.3745, Val NDCG@50: 0.5757\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 204 - Loss: 0.3736, Val NDCG@50: 0.5709\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 205 - Loss: 0.3680, Val NDCG@50: 0.5215\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 206 - Loss: 0.3750, Val NDCG@50: 0.5714\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 207 - Loss: 0.3671, Val NDCG@50: 0.5688\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 208 - Loss: 0.3653, Val NDCG@50: 0.5162\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 209 - Loss: 0.3699, Val NDCG@50: 0.5853\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 210 - Loss: 0.3610, Val NDCG@50: 0.6103\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 211 - Loss: 0.3617, Val NDCG@50: 0.5304\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 212 - Loss: 0.3568, Val NDCG@50: 0.5853\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 213 - Loss: 0.3609, Val NDCG@50: 0.6325\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 214 - Loss: 0.3580, Val NDCG@50: 0.6320\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 215 - Loss: 0.3576, Val NDCG@50: 0.5801\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 216 - Loss: 0.3557, Val NDCG@50: 0.6603\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 217 - Loss: 0.3543, Val NDCG@50: 0.5654\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 218 - Loss: 0.3562, Val NDCG@50: 0.6104\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 219 - Loss: 0.3538, Val NDCG@50: 0.6258\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 220 - Loss: 0.3542, Val NDCG@50: 0.5934\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 221 - Loss: 0.3523, Val NDCG@50: 0.5885\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 222 - Loss: 0.3445, Val NDCG@50: 0.6001\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 223 - Loss: 0.3494, Val NDCG@50: 0.5458\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 224 - Loss: 0.3484, Val NDCG@50: 0.5788\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 225 - Loss: 0.3482, Val NDCG@50: 0.5922\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 226 - Loss: 0.3375, Val NDCG@50: 0.6282\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 227 - Loss: 0.3510, Val NDCG@50: 0.6323\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 228 - Loss: 0.3457, Val NDCG@50: 0.6071\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 229 - Loss: 0.3430, Val NDCG@50: 0.6095\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 230 - Loss: 0.3437, Val NDCG@50: 0.5851\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 231 - Loss: 0.3390, Val NDCG@50: 0.6508\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 232 - Loss: 0.3441, Val NDCG@50: 0.6288\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 233 - Loss: 0.3421, Val NDCG@50: 0.5668\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 234 - Loss: 0.3347, Val NDCG@50: 0.6125\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 235 - Loss: 0.3337, Val NDCG@50: 0.5282\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 236 - Loss: 0.3323, Val NDCG@50: 0.6224\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 237 - Loss: 0.3310, Val NDCG@50: 0.5852\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 238 - Loss: 0.3345, Val NDCG@50: 0.6527\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 239 - Loss: 0.3286, Val NDCG@50: 0.6189\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 240 - Loss: 0.3314, Val NDCG@50: 0.5528\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 241 - Loss: 0.3276, Val NDCG@50: 0.6097\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 242 - Loss: 0.3304, Val NDCG@50: 0.5814\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 243 - Loss: 0.3310, Val NDCG@50: 0.5531\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 244 - Loss: 0.3341, Val NDCG@50: 0.5833\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 245 - Loss: 0.3323, Val NDCG@50: 0.5264\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 246 - Loss: 0.3297, Val NDCG@50: 0.5646\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 247 - Loss: 0.3275, Val NDCG@50: 0.6191\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 248 - Loss: 0.3304, Val NDCG@50: 0.6353\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 249 - Loss: 0.3245, Val NDCG@50: 0.5986\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 250 - Loss: 0.3229, Val NDCG@50: 0.5736\nTraining complete! Best validation NDCG@50: 0.6603\n","output_type":"stream"}],"execution_count":127}]}